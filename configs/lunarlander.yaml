env: LunarLander-v2
planner:
    batch_size: 32
    min_batches: 2
converter:
    type: flat
model:
    type: dense
    act_coef: 1
    vf_coef: 1
    ent_coef: 0.1
    ppo_clip: 0.1
    lr: 0.00025
    epochs: 4
    expected_value: -20
    normalize_advantage: True
    train_steps: 5000
    end_ppo_clip: 0.01
    end_lr: 0.000001
rewardShaper:
    discount_gamma: 0.99
    gae_lambda: 0.9
executor:
    samples: 32
    workers: 8
agent:
    end_reward: 0
    max_reward: 1000
