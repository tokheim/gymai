env: CarRacing-v1
planner:
    batch_size: 32
    min_batches: 2
converter:
    height: 48
    width: 48
    history: 3
model:
    type: conv
    act_coef: 1
    vf_coef: 1
    ent_coef: 0.03
    ppo_clip: 0.1
    lr: 0.003
    epochs: 3
    expected_value: 0.1
    normalize_advantage: True
    train_steps: 5000
    end_ppo_clip: 0.01
    end_lr: 0.000001
rewardShaper:
    discount_gamma: 0.9
    gae_lambda: 0.9
executor:
    samples: 32
    workers: 8
    rerun_prob: 0.05
agent:
    end_reward: -3.5
    max_reward: 1
    min_reward: -1
    stickiness: 3
actions:
- [-1, 0.05, 0]
- [1, 0.05, 0]
- [0, 1, 0]
- [0, 0, 1]
- [0, 0, 0]
